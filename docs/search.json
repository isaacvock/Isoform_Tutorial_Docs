[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to the EZbakR-suite isoform tutorial",
    "section": "",
    "text": "We recently put out a preprint introducing the first strategy for analyzing transcript isoform synthesis and degradation kinetics with NR-seq data from total RNA and the EZbakR-suite. To help others get this analysis strategy working in their hands, I developed this tutorial so as to show (with real data) how to go from FASTQ files to volcano plots using fastq2EZbakR to process the raw data and EZbakR to analyze the processed data. The data is hosted at this repository.\n\n\nThe dataset is a heavily downsampled version of the main NR-seq dataset presented in the preprint. It includes:\n\n3 replicates of DMSO treated, s4U fed data.\n3 replicates of SMG1 inhibitor (SMG1i) treated, s4U fed data.\n1 replicate of DMSO treated, -s4U data.\n1 replicate of SMG1i treated, -s4U data.\n\nThe fastq files included in the tutorial repo are downsampled to only include 5% of reads from a particular region of chromosome 6 (bases 16,103,264 to 57,096,698). Given how deeply the original dataset was sequenced, this leaves around 500,000 reads per fastq file. This region was chosen as it includes the SRSF3 gene, used as an example locus throughout the paper.\nSMG1 inhibition is designed to inhibit NMD. The goal of a transcript isoform-level analysis of this data is thus to identify transcripts that are stabilized upon NMD inhibition, as these are likely targets of NMD. SRSF3 is a gene that produces a well established NMD target (as well as a major isoform that is not degraded by NMD). If you do everything right, you should thus see the NMD degraded SRSF3 isoform coming up as significantly stabilized, whereas the other isoform should appear largely unaffected by SMG1i treatment.\n\n\n\nBy the end of this tutorial, you will have produced all of the output generated by fastq2EZbakR, as well as an EZbakRData object containing transcript isoform level analyses. In addition, this tutorial also showcases several other semi-orthogonal analysis strategies that can provide useful, sub-isoform level information (e.g., analyses of individual exon-exon junctions).\n\n\n\nMore details about the two main tools used in this tutorial can be found at their respective websites:\n\nfastq2EZbakR\nEZbakR"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Introduction to the EZbakR-suite isoform tutorial",
    "section": "",
    "text": "We recently put out a preprint introducing the first strategy for analyzing transcript isoform synthesis and degradation kinetics with NR-seq data from total RNA and the EZbakR-suite. To help others get this analysis strategy working in their hands, I developed this tutorial so as to show (with real data) how to go from FASTQ files to volcano plots using fastq2EZbakR to process the raw data and EZbakR to analyze the processed data. The data is hosted at this repository.\n\n\nThe dataset is a heavily downsampled version of the main NR-seq dataset presented in the preprint. It includes:\n\n3 replicates of DMSO treated, s4U fed data.\n3 replicates of SMG1 inhibitor (SMG1i) treated, s4U fed data.\n1 replicate of DMSO treated, -s4U data.\n1 replicate of SMG1i treated, -s4U data.\n\nThe fastq files included in the tutorial repo are downsampled to only include 5% of reads from a particular region of chromosome 6 (bases 16,103,264 to 57,096,698). Given how deeply the original dataset was sequenced, this leaves around 500,000 reads per fastq file. This region was chosen as it includes the SRSF3 gene, used as an example locus throughout the paper.\nSMG1 inhibition is designed to inhibit NMD. The goal of a transcript isoform-level analysis of this data is thus to identify transcripts that are stabilized upon NMD inhibition, as these are likely targets of NMD. SRSF3 is a gene that produces a well established NMD target (as well as a major isoform that is not degraded by NMD). If you do everything right, you should thus see the NMD degraded SRSF3 isoform coming up as significantly stabilized, whereas the other isoform should appear largely unaffected by SMG1i treatment.\n\n\n\nBy the end of this tutorial, you will have produced all of the output generated by fastq2EZbakR, as well as an EZbakRData object containing transcript isoform level analyses. In addition, this tutorial also showcases several other semi-orthogonal analysis strategies that can provide useful, sub-isoform level information (e.g., analyses of individual exon-exon junctions).\n\n\n\nMore details about the two main tools used in this tutorial can be found at their respective websites:\n\nfastq2EZbakR\nEZbakR"
  },
  {
    "objectID": "index.html#tutorial-setup",
    "href": "index.html#tutorial-setup",
    "title": "Introduction to the EZbakR-suite isoform tutorial",
    "section": "Tutorial setup",
    "text": "Tutorial setup\nTo get started, make git is installed on your system, clone the data repository locally, and navigate into it with:\n\ngit clone https://github.com/isaacvock/Isoform_Analysis_Tutorial.git\n\ncd Isoform_Analysis_Tutorial\n\nInside of Isoform_Analysis_Tutorial, you will find a directory called data. Unzip the GTF and FASTA files in this folder:\n\ngzip -d data/hg38_*\n\nOnce you are ready, proceed to the fastq2EZbakR portion of this tutorial!"
  },
  {
    "objectID": "fastq2EZbakR.html#quickstart",
    "href": "fastq2EZbakR.html#quickstart",
    "title": "fastq2EZbakR for isoform analyses",
    "section": "Quickstart",
    "text": "Quickstart\n\n# CREATE ENVIRONMENT\nmamba create -c conda-forge -c bioconda --name deploy_snakemake 'snakemake&lt;8.0.0' snakedeploy\n  # Or conda create ...\n  # If using conda, I would highly suggest setting up the\n  # libmamba solver: https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community\n\n# DEPLOY PIPELINE\nconda activate deploy_snakemake\nsnakedeploy deploy-workflow https://github.com/isaacvock/fastq2EZbakR.git . --branch main\n\n###\n# EDIT CONFIG FILE\n###\n\n# RUN PIPELINE\nsnakemake --cores all --use-conda --rerun-triggers mtime --keep-going"
  },
  {
    "objectID": "fastq2EZbakR.html#running-the-pipeline",
    "href": "fastq2EZbakR.html#running-the-pipeline",
    "title": "fastq2EZbakR for isoform analyses",
    "section": "Running the pipeline",
    "text": "Running the pipeline\n\nStep 0: Setup\nfastq2EZbakR uses Conda/Mamba to automatically install all necessary dependencies the first time you run the pipeline. Thus, you should install one of these before running fastq2EZbakR.\nHistorically, I have suggested installing Mamba over Conda, as Mamba was often orders of magnitude faster than Conda for fastq2EZbakR dependency installation. Recently though, Conda has added support for using the same underlying solver that Mamba uses (libmamba). Thus, if you already have Conda installed, check out this documentation for how to configure the faster solver.\nOnce you have mamba/conda installed, create a conda environment with Snakemake and Snakedeploy installed:\n\nmamba create -c conda-forge -c bioconda --name deploy_snakemake 'snakemake&lt;8.0.0' snakedeploy\n# Or conda create ...\n\nInstalling a Snakemake version &lt; 8.0.0 is not strictly necessary for using fastq2EZbakR, but it insures compatibility with some of the HPC deployment strategies documented here.\n\n\nStep 1: Deploy\nActive your conda environment and “deploy” fastq2EZbakR like so:\n\nconda activate deploy_snakemake\nsnakedeploy deploy-workflow https://github.com/isaacvock/fastq2EZbakR.git . --branch main\n\nThis will create two new directories: config and workflow. config will include the config.yaml file that specifies what your input to the pipeline will be and sets a number of parameters that tunes how the pipeline is run. workflow contains a singular Snakefile that specifies the link at which all of the pipeline code is hosted. This is a convenient way to deploy a Snakemake pipeline, as it avoids you having to clone the entire repo and thus makes it easier to stay up-to-date with the most current pipeline version.\n\n\nStep 2: Edit the config file\nAssuming you are in the directory created when you clone the tutorial data repo as described in the intro, you should have a folder called data which shoud contain:\n\nhg38_chr6_subseq.fa: FASTA file to align reads to\nhg38_refseq_subseq.gtf: RefSeq GTF file with genomic feature coordinates, used for feature assignment of reads and transcript isoform quantification.\nfastqs: directory containing a number of sub-directories, each containing a pair of FASTQ files.\n\nIn practice, you will have to download a relevant genome FASTA file and annotation GTF file yourself. Furthermore, in the preprint we advocate for using your RNA-seq data to augment and filter a conservative reference (like RefSeq for human data; Ensembl annotations filtered for high support level isoforms would also be acceptable) with StringTie or similar tools. Our personal annotation assembly strategy (StringTie + post-hoc trimming/isoform flagging discussed in preprint and here) is implemented in a Snakemake pipeline called AnnotationCleaner.\nYou need to edit the following sections of your config file to specify input data and desired pipeline settings for isoform-level analyses:\nsamples\nPaths to FASTQ file containing directories. Each directory should contain a single FASTQ file (for single-end data) or a pair of FASTQ files (for paired-end data).\n\nsamples:\n    DMSO_8hr_1: data/fastqs/DMSO_8hr_1\n    DMSO_8hr_2: data/fastqs/DMSO_8hr_2\n    DMSO_8hr_3: data/fastqs/DMSO_8hr_3\n    DMSO_8hr_nos4U: data/fastqs/DMSO_8hr_nos4U\n    SMG1i_8hr_1: data/fastqs/SMG1i_8hr_1\n    SMG1i_8hr_2: data/fastqs/SMG1i_8hr_2\n    SMG1i_8hr_3: data/fastqs/SMG1i_8hr_3\n    SMG1i_8hr_nos4U: data/fastqs/SMG1i_8hr_nos4U\n\ncontrol_samples\nThis specifies which samples are -s4U samples and should thus be used for SNP calling. In practice, if you have lots of -s4U samples, you only need to specify 1 or 2 of them:\n\ncontrol_samples: ['SMG1i_8hr_nos4U', 'DMSO_8hr_nos4U']\n\nPE\nSpecify whether library is paired-end. Soon this will be automatically detected, but for now you need to tell fastq2EZbakR that this is a paired-end dataset\n\nPE: True\n\ngenome\nSpecify the path to the genome FASTA file. This can be relative to the directory in which you will run Snakemake (i.e., the top of the Isoform_Analysis_Tutorial direcotry), or an absolute path to the file:\n\ngenome: data/hg38_chr6_subseq.fa\n\nannotation\nSpecify the path to the genome annotation GTF file. Again, relative or absolute paths are acceptable. The example here is a relative path as in the genome example:\n\nannotation: data/hg38_refseq_chr6subseq.gtf\n\nindices\nRelative or absolute path to, and name of, directory created to contain alignment indicies. You need to use STAR (the default fastq2EZbakR aligner) for transcript-isoform level analyses and so I have chosen to name it to reflect that aligner choice:\n\nindices: data/star_chr6_subseq\n\nstrandedness\nStrandedness of your library. This data is reverse stranded, meaning that the first read in a pair represents the reverse complement of the original RNA’s sequence:\n\nstrandedness: \"reverse\"\n\nfeatures\nThis is the key part. For transcript isoform level analyses, you need to turn on assignment of reads to their transcript equivalence class (TEC; tec in config). Here, I have also turned on two other non-default feature assignment strategies: assignment of reads to exonic bins (like in DEXSeq) and exon-exon junctions. We will use these two strategies in the EZbakR portion of the tutorial as they provide complementary information to the TEC analysis:\n\nfeatures:\n  genes: True\n  exons: True\n  tec: True\n  exonic_bins: True\n  junctions: True\n  eej: False\n  eij: False\n\nflat_annotation\nScroll down a bit and you will see this parameter. Since I have specified exonic_bins to True in features, a DEXSeq flattened annotation will be created. The flat_annotation parameter allows you to specify the name and location of this annotation:\n\nflat_annotation: \"data/hg38_chr6subseq_flat.gtf\"\n\nfinal_output\nScroll down further and you will see the final_output parameter. The default will work fine here, but to get you some useful experience, I would suggest also turning on the arrow output, as this can be helpful when working with larger datasets using EZbakR. I’ll show you how in the EZbakR portion of this tutorial:\n\nfinal_output:\n  cB: True\n  cUP: False\n  arrow: True\n\nstar_sam_tags\nKeep scrolling down and you will see the star_sam_tags parameter. This specifies which additional bam file tags to include in the STAR alignment output. Since I specified the junction feature assignment (junctions: True in features), you should specify the STAR-specific junction information tags (jI and jM):\n\nstar_sam_tags: [\"NH\", \"HI\", \"AS\", \"NM\", \"MD\", \"nM\", \"jI\", \"jM\"]\n\nOther parameters\nEverything else can be left as is for this analysis, but some other parameters you may want to edit for your own analyses include:\n\nfastp_adapters and fastp_parameters: The former specifies adapter sequences for fastp to trim, and the latter specifies optional trimming parameters. I often like to do some conservative trimming, which may look like setting fastp_parameters to \"--trim_poly_x --cut_tail --cut_front --trim_tail1 3 --trim_front1 3 --trim_front2 3 --trim_tail2 3\", which hard trims the ends of all reads and also does some polyA/G and low quality base trimming.\nstar_align_params: This sets optional arguments for STAR alignment. The default config file has some standard settings that I would suggest, including lenient mismatch penalization and end-to-end alignment (rather than allowing soft-clipping). The latter is important for assignment of reads to exons, as soft-clipping can mess with this strategy (as discussed in the docs).\n\n\n\nStep 3: Run pipeline\nNavigate to the top of the Isoform_Analysis_Tutorial directory and do a dry run of the pipeline with :\n\nsnakemake -n --cores all --use-conda --rerun-triggers mtime --keep-going\n\nThe -n flag makes this a “dry run”, which means that it just checks to see if the pipeline can be run as configured, throws an informative error if it finds something wrong, and tells you all of the steps that will be run if everything looks good. You can then actually run the pipeline by removing this flag:\n\nsnakemake --cores all --use-conda --rerun-triggers mtime --keep-going\n\nWith this downsampled dataset and a 4 core laptop, the full pipeline should take about 20 minutes to run with this strategy. By default, all of the steps in the pipeline will run serially (i.e., one after another). This is often not the best way to run fastq2EZbakR, or any Snakemake pipeline. If you are running the pipeline in an HPC environment, there are several ways to get Snakemake to more effectively use all of the resources available to you, and to thus run each step of the pipeline as a separate job, with several jobs able to be queued up in parallel in many cases. See here and here for some details. If you are using Snakemake version &gt;= 8.0.0, checkout the executor plug-ins here."
  },
  {
    "objectID": "fastq2EZbakR.html#next-steps",
    "href": "fastq2EZbakR.html#next-steps",
    "title": "fastq2EZbakR for isoform analyses",
    "section": "Next steps",
    "text": "Next steps\nIf everything ran smoothly, you are ready to move on to the EZbakR portion of this tutorial! The cheatsheet directory of this tutorial repo contains the important expected output, if you want to compare what you got to the “right answers”. You can also use the data in cheatsheet in case you want to skip right to the EZbakR portion without waiting for fastq2EZbakR to finish running."
  },
  {
    "objectID": "fastq2EZbakR.html",
    "href": "fastq2EZbakR.html",
    "title": "fastq2EZbakR for isoform analyses",
    "section": "",
    "text": "The first step towards an isoform-level analysis of your NR-seq data is to process your data with fastq2EZbakR. Crucially, fastq2EZbakR will count mutations in your sequencing reads (necessary for all NR-seq analyses) and combine this with information as to the set of transcript isoforms in your annotation with which each read is compatible (TEC assignment; necessary for isoform-level analyses). The main output of this pipeline, which will be found in the results/cB/ after completion, will be the input for the EZbakR isoform-level analysis."
  },
  {
    "objectID": "fastq2EZbakR.html#introduction",
    "href": "fastq2EZbakR.html#introduction",
    "title": "fastq2EZbakR for isoform analyses",
    "section": "",
    "text": "The first step towards an isoform-level analysis of your NR-seq data is to process your data with fastq2EZbakR. Crucially, fastq2EZbakR will count mutations in your sequencing reads (necessary for all NR-seq analyses) and combine this with information as to the set of transcript isoforms in your annotation with which each read is compatible (TEC assignment; necessary for isoform-level analyses). The main output of this pipeline, which will be found in the results/cB/ after completion, will be the input for the EZbakR isoform-level analysis."
  },
  {
    "objectID": "EZbakR.html#isoform-level-analyses",
    "href": "EZbakR.html#isoform-level-analyses",
    "title": "EZbakR for isoform analyses",
    "section": "Isoform-level analyses",
    "text": "Isoform-level analyses\n\nQuickstart\nHere is the code that I will walk through more thoroughly in the next subsection:\n\n##### Load dependencies #####\n\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(EZbakR)\n\n##### Create EZbakRData object #####\n\ncB &lt;- fread(\"path/to/cB/cB.csv.gz\")\n\nmetadf &lt;- tibble(\n  sample = unique(cB$sample)\n) %&gt;%\n  dplyr::mutate(\n    tl = ifelse(grepl(\"nos4U\", sample),\n                0, 2),\n    treatment = ifelse(grepl(\"^DMSO\", sample),\n                       \"DMSO\",\n                       \"SMG1i\")\n  )\n\nezbdo &lt;- EZbakRData(cB, metadf)\n\n\n##### Estimate TEC fraction news #####\n\nezbdo &lt;- EstimateFractions(ezbdo,\n                           pold_from_nolabel = TRUE,\n                           features = c(\"XF\", \"TEC\"),\n                           filter_condition = `|`)\n\n\n##### Estimate transcript isoform fraction news #####\n\n### Load isoform quantification information\nfile_names &lt;- list.files(path = \"path/to/rsem/\",\n                         pattern = \"isoform\",\n                         full.names = TRUE)\nnames(file_names) &lt;- metadf$sample\n\n### Deconvolve isoform fraction news\n\nezbdo &lt;- ImportIsoformQuant(ezbdo,\n                            files = file_names,\n                            quant_tool = \"rsem\")\n\n##### Estimate, average, and compare degradation rate constants #####\n\nezbdo &lt;- EstimateIsoformFractions(ezbdo)\n\n\nezbdo &lt;- EstimateKinetics(ezbdo, features = \"transcript_id\",\n                          exactMatch = FALSE)\n\nezbdo &lt;- AverageAndRegularize(ezbdo, features = \"transcript_id\",\n                              exactMatch = FALSE)\n\nezbdo &lt;- CompareParameters(ezbdo,\n                           features = \"transcript_id\",\n                           design_factor = \"treatment\",\n                           reference = \"DMSO\",\n                           experimental = \"SMG1i\",\n                           exactMatch = FALSE)\n\n\n##### Assess results #####\n\nEZVolcanoPlot(ezbdo)\n\n\ncomparison &lt;- EZget(ezbdo,\n                    type = \"comparisons\")\n\n\ncomparison %&gt;%\n  filter(XF == \"SRSF3\")\n\n\n\nStep 1: Create EZbakRData object\n\n\nStep 2: Estimate TEC fraction news\n\n\nStep 3: Estimate isoform fraction news\n\n\nStep 4-6: Estimate, average, and compare rate constants"
  },
  {
    "objectID": "EZbakR.html#alternative-feature-analyses",
    "href": "EZbakR.html#alternative-feature-analyses",
    "title": "EZbakR for isoform analyses",
    "section": "Alternative feature analyses",
    "text": "Alternative feature analyses\n\nWhy?\n\n\nHow?"
  },
  {
    "objectID": "EZbakR.html",
    "href": "EZbakR.html",
    "title": "EZbakR for isoform analyses",
    "section": "",
    "text": "This part of the tutorial shows you how to use EZbakR and the output of fastq2EZbakR to perform an isoform-level analysis of NR-seq data. There are steps to this analysis:\n\nCreate EZbakRData object\nEstimate TEC fraction news\nEstimate isoform fraction news\n\nLinear mixing model using TEC fraction news + isoform abundance estimates\n\nConvert fraction news to rate constants\nAverage replicate data\nCompare kinetic parameter estimates between SMG1i and DMSO samples\n\nThis tutorial will also show you how to perform and make use of alternative feature assignment strategies."
  },
  {
    "objectID": "EZbakR.html#introduction",
    "href": "EZbakR.html#introduction",
    "title": "EZbakR for isoform analyses",
    "section": "",
    "text": "This part of the tutorial shows you how to use EZbakR and the output of fastq2EZbakR to perform an isoform-level analysis of NR-seq data. There are steps to this analysis:\n\nCreate EZbakRData object\nEstimate TEC fraction news\nEstimate isoform fraction news\n\nLinear mixing model using TEC fraction news + isoform abundance estimates\n\nConvert fraction news to rate constants\nAverage replicate data\nCompare kinetic parameter estimates between SMG1i and DMSO samples\n\nThis tutorial will also show you how to perform and make use of alternative feature assignment strategies."
  }
]